{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulbhoyar1995/HuggingFace-Tutorials/blob/main/1_Accessing_Pre_Trained_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Author : Rahul Bhoyar"
      ],
      "metadata": {
        "id": "5B9XeiYKfkbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csvam2nOBEgO",
        "outputId": "c9bfe1da-3c3a-4936-ebdf-0d055cd0be1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing Pre-Trained Models Directly\n",
        "\n",
        "\n",
        "Model Card: https://huggingface.co/gpt2"
      ],
      "metadata": {
        "id": "TzGAX8ZlH6f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX-MZyASHi6y",
        "outputId": "46bcca74-5828-49b2-96af-e9679b62a102"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode context the generation is conditioned on\n",
        "model_inputs = tokenizer('I am a Python Programmer and I must', return_tensors='pt')\n",
        "\n",
        "# generate 40 new tokens\n",
        "greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tALfu1FBHq3y",
        "outputId": "834df00a-a35b-4357-db8f-d3256839decc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am a Python Programmer and I must say that I am very impressed with the way the code is written. I am also very impressed with the way the code is written. I am also very impressed with the way the code is written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing Pre-trained Models Using Pipeline\n",
        "\n",
        "\n",
        "A Hugging Face **pipeline** is a high-level abstraction for running inference on models from the Hugging Face Model Hub. It simplifies the process of using pre-trained models for various tasks such as language understanding, computer vision, and speech recognition.\n",
        "\n",
        "With the `pipeline()` function, users can easily load models and tokenizers, and perform inference without requiring expertise in the underlying models. Users can specify an inference task, provide input data, and the pipeline will automatically handle pre-processing, model inference, and post-processing.\n",
        "\n",
        "**Pipeline** supports multiple modalities including text, audio, and vision, and allows users to easily switch between different models for improved results."
      ],
      "metadata": {
        "id": "sPYf9kKKIB0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (A) Model 1 : GPT-2"
      ],
      "metadata": {
        "id": "vC-wzlmvgmEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2\")"
      ],
      "metadata": {
        "id": "ejt0nCeqHxov"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe('I am a Python Programmer and I must', max_length=30, num_return_sequences=1,truncation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPRA6cX_IXNP",
        "outputId": "2c0b5287-2aef-4580-894a-7de102b4a7a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I am a Python Programmer and I must give you my first ever job, a job that will make you feel even better even without the Python program'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe('Machine Learning is fun because', max_length=30, num_return_sequences=5,truncation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGj4y116IadD",
        "outputId": "6b6432d9-cba7-49e2-ba3d-d9fb500af935"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Machine Learning is fun because there is a lot of stuff there that people come to know, but with a lot of complexity it was hard at first to'},\n",
              " {'generated_text': \"Machine Learning is fun because you learn things and you learn from them.\\n\\nIf you are in those circles, we're not sure how you feel\"},\n",
              " {'generated_text': 'Machine Learning is fun because it is a fast, simple, and intuitive model of deep learning. The fact remains, while deep learning can be useful to'},\n",
              " {'generated_text': 'Machine Learning is fun because it shows you very little. It can take an idea and show it right away but it also does the most important thing that'},\n",
              " {'generated_text': 'Machine Learning is fun because it makes you think much less of the stuff you actually want â€“ it gives you time without sacrificing accuracy. And yet in those'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this way you can interact with any open source model on Hugging Face."
      ],
      "metadata": {
        "id": "ezNwLzEWgdic"
      }
    }
  ]
}